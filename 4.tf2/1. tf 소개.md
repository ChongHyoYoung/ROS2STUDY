# 1. tf 소개





**TF 변환 관리(TF Transformation Management):** tf2는 로봇의 다양한 하드웨어 구성 요소 및 프레임 간의 변환 관계를 관리합니다. 이것은 로봇의 다양한 부분 간에 상대 위치와 방향을 표현하는 데 사용됩니다. 예를 들어, 로봇의 기준 프레임(base_link)과 레이저 스캐너 프레임(laser_frame) 간의 변환 정보를 추적하고 갱신하는 데 tf2를 사용할 수 있습니다.

**TF 변환 브로드캐스터(TF Transformation Broadcaster)**: 로봇 소프트웨어에서 tf2를 사용하여 변환 데이터를 게시(broadcast)할 수 있습니다. 이를 통해 로봇의 각 하드웨어 구성 요소가 현재 위치와 방향 정보를 다른 구성 요소 및 노드와 공유할 수 있습니다.

**TF 변환 리스너(TF Transformation Listener)**: tf2를 사용하여 로봇 소프트웨어에서 TF 변환 데이터를 구독(subscribe)하고 현재 변환 정보를 가져올 수 있습니다. 이를 통해 로봇 제어 노드는 로봇의 현재 위치와 방향 정보를 실시간으로 수신하고 사용할 수 있습니다.

**TF 변환 시각화(TF Transformation Visualization):** tf2는 변환 정보를 시각화하고 디버깅하기 위한 도구도 제공합니다. 예를 들어, RViz와 같은 시각화 도구에서 TF 변환 정보를 시각화하여 로봇의 상태를 모니터링할 수 있습니다.

**다양한 프레임 관리(Management of Various Frames):** tf2를 사용하여 로봇 시스템에서 다양한 프레임을 관리하고 변환할 수 있습니다. 이는 로봇 암, 카메라, 레이더, 자이로스코프, IMU 등 다양한 하드웨어 구성 요소 간의 상대 위치 및 방향을 추적하는 데 중요합니다.

ROS 2에서 tf2는 geometry_msgs/TransformStamped와 같은 메시지 유형을 사용하여 변환 정보를 표현하며, Python 및 C++을 포함한 다양한 ROS 2 언어 클라이언트에서 사용할 수 있습니다. TF 변환 라이브러리를 사용하면 로봇 소프트웨어 개발 및 로봇 제어 작업을 훨씬 효율적으로 수행할 수 있습니다.



## 실습



데모를 하기전에 사전에 아래의 패키지를 설치해야 한다.

demo package와 dependencies 설치

```
sudo apt-get install ros-humble-turtle-tf2-py ros-humble-tf2-tools ros-humble-tf-transformations
```

새로운 터미널을 실행한 후, ROS2 설치를 source하고 다음 명령어를 실행한다.

```
ros2 launch turtle_tf2_py turtle_tf2_demo.launch.py
```

<img src="https://github.com/firstbot1/ROS2STUDY/blob/main/4.tf2/pic/1_1.png" alt="이미지 대체 텍스트" style="float: left;">

위 사진과 같이 두 개의 turtle이 실행되는 것을 볼 수 있다. 새로운 터미널을 실행한 후, 다음 명령어를 실행한다.

```
ros2 run turtlesim turtle_teleop_key
```

![](/home/firstbot/ROS2/readme_tf2/pic/1_2.png)

위 사진처럼, 키보드를 이용해 하나의 turtle을 움직여보면, 또 다른 turtle이 따라오는 것을 확인 할 수 있다.

- tf2 library는 3개의 프레임(world, turtle1, turtle2)을 생성한다.
- tf2 broadcaster는 turtle들의 프레임을 publish한다.
- tf2 listener는 두 프레임 사이의 차이를 계산하고, 하나의 turtle을 움직여 다른 turtle을 따라가도록 한다.



## 1. tf2 tools : view_frames 사용하기



tf2_tools을 활용하여 tf2가 이 데모에서 어떻게 사용되고 있는지 살펴보자.

```
ros2 run tf2_tools view_frames
```

[INFO] [1695363294.225625945] [view_frames]: Result:tf2_msgs.srv.FrameGraph_Response(frame_yaml="turtle2: \n  parent: 'world'\n  broadcaster: 'default_authority'\n  rate: 50.725\n  most_recent_transform: 1695363294.208544\n  oldest_transform: 1695363289.181451\n  buffer_length: 5.027\nturtle1: \n  parent: 'world'\n  broadcaster: 'default_authority'\n  rate: 51.297\n  most_recent_transform: 1695363294.211716\n  oldest_transform: 1695363289.182196\n  buffer_length: 5.030\n")

![](/home/firstbot/ROS2/readme_tf2/pic/1_3.png)

![](/home/firstbot/ROS2/readme_tf2/pic/1_4.png)



위 tree에서, tf2가 broadcast하고 있는 world/turtlr1/turtlr2 프레임들을 확인 할 수 있다. 여기서 world프레임은 turtle1과 turtle2의 부모 프레임이다. 또한, 최초 및 최신 transform이나 publish 주기와 같은 디버깅용 정보도 함께 표시해 준다.



## 2.tf2_echo 사용하기



tf2_echo는 broadcast되고 있는 임의의 두 프레임간의 transform을 출력해 준다.

*ros2 run tf2_ros tf2_echo [reference_frame] [target_frame]*

현재 터미널에서 아래 명령어를 실행하여, turtlr1 프레임에 대한 turtle2 프레임의 transform을 출력해보자

```
ros2 run tf2_ros tf2_echo turtle2 turtle1
```

At time 1670314455.630744254

\- Translation: [0.000, 0.000, 0.000]

\- Rotation: in Quaternion [0.000, 0.000, 0.247, 0.969]

\- Rotation: in RPY (radian) [0.000, -0.000, 0.499]

\- Rotation: in RPY (degree) [0.000, -0.000, 28.599]

\- Matrix:

  0.878 -0.479  0.000  0.000

  0.479  0.878  0.000  0.000

  0.000  0.000  1.000  0.000

  0.000  0.000  0.000  1.000

이 정보(transform)는 주로 로봇 시스템에서 한 프레임에서 다른 프레임으로의 변환을 설명하는 데 사용됩니다. 여기에 나열된 각 항목의 의미는 다음과 같습니다:

**Translation**: [0.000, 0.000, 0.000]: 이 부분은 **변환의 위치(Translation)**를 나타냅니다. [X, Y, Z] 형식으로 표현되며, 여기서는 X

**1. x (가로축)**: x는 오브젝트의 위치를 가로축(좌에서 우)으로 나타냅니다. 양의 x 값은 오른쪽 방향으로, 음의 x 값은 왼쪽 방향으로 이동함을 의미합니다.

**2. y (세로축)**: y는 오브젝트의 위치를 세로축(위에서 아래)으로 나타냅니다. 양의 y 값은 아래 방향으로, 음의 y 값은 위 방향으로 이동함을 의미합니다.

**3. z (높이 또는 깊이)**: z는 오브젝트의 위치를 높이(높이를 측정하는 경우) 또는 깊이(깊이를 측정하는 경우)로 나타냅니다. 양의 z 값은 위로 또는 높이가 높은 방향으로, 음의 z 값은 아래로 또는 깊이가 낮은 방향으로 이동함을 의미합니다.



**Rotation:** in Quaternion [0.000, 0.000, 0.247, 0.969]: 이 부분은 변환의 회전(Rotation)을 **쿼터니언(quaternion) 형식으로 나타냅니다. [X, Y, Z, W] 형식으로 표현되며, 여기서 X, Y, Z, W 값이 순서대로 나열되어 있습니다. 쿼터니언은 회전을 나타내는 수학적인 방법 중 하나이며, 여기서는 X=0.000, Y=0.000, Z=0.247, W=0.969로 회전을 나타냅니다.

**1. x (벡터 부분)**: Quaternion의 x 부분은 회전 축의 방향을 나타내는 벡터 부분 중 하나입니다. 이 부분은 회전을 수행하는 3D 공간에서의 축의 방향을 정의합니다. Quaternion은 회전을 이 축을 중심으로 수행합니다.

**2. y (벡터 부분)**: Quaternion의 y 부분은 또 다른 회전 축의 방향을 나타내는 벡터 부분입니다. 이 부분은 또 다른 회전을 수행하는 3D 공간에서의 축의 방향을 정의합니다.

**3. w (스칼라 부분)**: Quaternion의 w 부분은 스칼라 부분이며, 회전의 강도 또는 회전의 크기를 나타냅니다. 이 값은 회전의 "크기"를 나타내며, 회전한 후의 좌표계의 방향에 대한 정보를 제공합니다. 일반적으로 0과 1 사이의 값을 가지며, 1인 경우 완전한 회전을 나타냅니다.

**4. z (벡터 부분)**: Quaternion의 z 부분은 벡터 부분이며, 회전 축을 나타냅니다. 이 부분은 회전 축의 방향을 3D 공간에서 지정하는 데 사용됩니다. 이 벡터는 3D 공간에서 회전을 수행하는 축을 정의하며, 회전 축의 방향 벡터를 나타냅니다.

Quaternion은 주로 회전을 표현하는 데 사용되며, 스칼라와 벡터 부분은 함께 사용하여 회전의 크기와 방향을 나타냅니다. Quaternion은 Euler 각도와 비교하여 특히 회전 문제를 다룰 때 유용하며, 회전을 선형 보간하거나 조작할 때 특히 효과적입니다.

Quaternion의 x, y, z 부분은 모두 회전 축의 방향을 나타내며, 이러한 축을 중심으로 회전이 이루어집니다. Quaternion은 회전을 세 개의 축 주위로 표현하는 데 사용되며, 이러한 방식으로 회전을 더 효율적으로 나타낼 수 있습니다. Quaternion을 사용하면 회전 표현이 Euler 각도보다 훨씬 간단하고 유용하며, 회전 조작 및 계산에 유용합니다.

Rotation: in RPY (degree) [0.000, -0.000, 28.599]: 이 부분은 변환의 회전을 롤-피치-요(Yaw) 각도로 나타냅니다. 각도는 도(degree) 단위로 표현되며, [Roll, Pitch, Yaw] 형식으로 표현됩니다. 여기서는 Roll=0.000, Pitch=-0.000, Yaw=28.599도로 회전을 나타냅니다.

Rotation은 물체나 좌표 프레임의 회전을 나타내는 것으로, 주로 roll, pitch, yaw로 표현됩니다. 각각의 용어는 다음과 같이 정의됩니다:

1. **Roll (롤)**: 롤은 물체나 좌표 프레임이 x 축 주위로 회전하는 것을 나타냅니다. 롤 각도는 x 축 주위의 회전 각도로, 양의 롤 각도는 시계 방향으로 회전함을 나타내며, 음의 롤 각도는 반시계 방향으로 회전함을 나타냅니다.
2. **Pitch (피치)**: 피치는 물체나 좌표 프레임이 y 축 주위로 회전하는 것을 나타냅니다. 피치 각도는 y 축 주위의 회전 각도로, 양의 피치 각도는 시계 방향으로 회전함을 나타내며, 음의 피치 각도는 반시계 방향으로 회전함을 나타냅니다.
3. **Yaw (요)**: 요는 물체나 좌표 프레임이 z 축 주위로 회전하는 것을 나타냅니다. 요 각도는 z 축 주위의 회전 각도로, 양의 요 각도는 시계 방향으로 회전함을 나타내며, 음의 요 각도는 반시계 방향으로 회전함을 나타냅니다.

이러한 각도들은 공간에서 물체의 방향을 나타내는 데 사용되며, 일반적으로 오일러 각도 또는 회전 행렬의 형태로 표현됩니다. Roll, pitch, yaw를 조합하여 물체의 회전을 정확하게 표현할 수 있습니다.

![](/home/firstbot/ROS2/readme_tf2/pic/1_5.png)

**Matrix:** 이 부분은 변환을 나타내는 4x4 변환 행렬을 표시합니다. 변환 행렬은 위치(Translation) 및 회전(Rotation) 정보를 모두 포함하며, 4x4 행렬로 표현됩니다. 여기에 표시된 값은 변환 행렬의 각 요소를 나타냅니다. 변환 행렬의 각 요소는 위치, 회전 및 크기를 나타내며, 여기서는 크기가 변환에 영향을 미치지 않으므로 1.000으로 표시됩니다. 이 변환 행렬은 다른 프레임 간의 변환을 정확하게 정의합니다.

이 행렬은 4x4 행렬로서, 일반적으로 3D 변환 매트릭스라고 합니다. 각 행렬 요소는 다음과 같이 해석됩니다:

1. **첫 번째 행 (1행)**:

- 0.878: x 축 방향의 스케일링 요소
- -0.479: y 축 방향의 회전 및 스케일링 요소
- 0.000: z 축 방향의 회전 및 스케일링 요소
- 0.000: x 축에 대한 변환

1. **두 번째 행 (2행)**:

- 0.479: x 축 방향의 회전 및 스케일링 요소
- 0.878: y 축 방향의 스케일링 요소
- 0.000: z 축 방향의 회전 및 스케일링 요소
- 0.000: y 축에 대한 변환

1. **세 번째 행 (3행)**:

- 0.000: x 축 방향의 회전 및 스케일링 요소
- 0.000: y 축 방향의 회전 및 스케일링 요소
- 1.000: z 축 방향의 스케일링 요소
- 0.000: z 축에 대한 변환

1. **네 번째 행 (4행)**:

- 0.000: x, y, z 축에 대한 변환
- 1.000: 확장 및 스케일링을 나타내는 요소

이 행렬은 3D 변환을 표현하며, 스케일링, 회전 및 변환 정보를 함께 포함합니다. 이 변환 행렬을 사용하면 3D 객체를 다른 좌표 공간으로 변환하거나 확장 및 회전시킬 수 있습니다.

이 정보는 로봇 시스템에서 프레임 간의 변환을 나타내는 데 사용되며, 주로 로봇 운동학 및 위치 추정에 적용됩니다. 변환 정보는 로봇의 센서 데이터, 관절 각도 등을 다른 프레임으로 변환하는 데 사용되며, 로봇 시스템의 상호작용 및 제어에 중요한 역할을 합니다.



## 3.rviz와 tf2



rviz는 tf2 프레임들을 테스트할때 유용한 시각화 툴이다. rviz를 이용하여 turtle 프레임을 확인해보자. 아래 명령과 같이 -d 옵션으로 turtle_rviz.rviz 설정파일이 적용된 rviz를 실행해보자.

```
ros2 run rviz2 rviz2 -d $(ros2 pkg prefix --share turtle_tf2_py)/rviz/turtle_rviz.rviz
```

![](/home/firstbot/ROS2/readme_tf2/pic/1_6.png)

왼쪽 Displays 패널의 TF-frames 항목을 보면, tf2에 의해 broadcast되고 있는 프레임들을 확인해 볼 수 있다. 또한 키보드로 turtle을 움직이면, rviz상에서 프레임들이 따라 움직이는 모습을 볼 수 있다.



====================================================================================

Q. ros2 launch turtle_tf2_py turtle_tf2_demo.launch.py 와 ros2 run turtlesim turtle_teleop_key을 실행 했을 때 왜 Fixed Frame에 world가 생성되야 하나요?

A. "Fixed Frame" 설정이 "world"로 설정되어야 하는 이유는 **ROS 2에서 tf2 시스템과 시각화 도구 (예: rviz2) 간의 연동 및 변환 관계를 설정하는 데 사용되기 때문**입니다. **"Fixed Frame"은 일반적으로 시각화 도구에서 표시된 모든 객체의 기준이 되는 고정된 좌표 프레임을 나타냅니다**. 이렇게 하면 시각화 도구에서 로봇 및 다른 객체의 상대적인 위치 및 방향을 올바르게 표시할 수 있습니다.

여기서 "world"라는 이름의 고정된 좌표 프레임은 일반적으로 전역 좌표 프레임으로 사용됩니다. 이 좌표 프레임은 로봇 및 환경의 모든 다른 객체의 상대적인 위치 및 방향을 기준으로 표시하는 데 사용됩니다. 따라서 로봇 및 환경을 시각화하고 테스트할 때 "Fixed Frame"이 "world"로 설정되어야 합니다.

실제로 "turtle_tf2_demo.launch.py"와 "turtle_teleop_key"를 실행하면 시뮬레이션 환경에서 거북이 로봇이 움직이게 되고, 이 로봇의 움직임은 "world" 좌표 프레임을 기준으로 시각화되므로 "Fixed Frame"을 "world"로 설정해야 올바른 시각화를 볼 수 있습니다. "Fixed Frame"을 "world"로 설정하면 로봇의 상대적인 위치와 방향이 "world" 좌표 프레임을 기준으로 표시됩니다.



< ft2, urdf ref site>

[](https://articulatedrobotics.xyz/ready-for-ros-6-tf/)

tf2는 아래와 같이 로봇 제작시 현실적인 과정에서 필요하다.

라이다와 좌우에 오도메트리 휠을 이용한 로봇을 만들고자 할 때의 tf2 tree 구조는 어떠할지? GPT에 물어 보았다.



Q. 라이다가 중앙에 있고 좌우에 2개의 오도메터리가 장착된 바퀴가 있다면 tf2에서 프레임의 이름은 각각 어떻게 해야 하나?

A. 로봇 시스템에서 프레임의 이름을 지정할 때, 일반적으로 다음과 같은 관례를 따릅니다. 여기에서는 중앙에 라이다(LIDAR) 센서가 있고 좌우에 2개의 오도메터리(휠)가 장착된 로봇을 예로 들겠습니다. 이러한 구성에 대한 프레임 이름을 지정할 때는 다음과 같은 프레임을 고려할 수 있습니다:

1. **base_link (기준 프레임):** "base_link" 프레임은 로봇의 중심 또는 기준점에 해당합니다. 이 프레임은 로봇의 위치 및 자세 정보를 나타내며, 일반적으로 로봇의 기준 좌표 프레임으로 사용됩니다.
2. **laser_frame (라이다 프레임):** "laser_frame" 프레임은 라이다 센서가 부착된 위치와 방향을 나타냅니다. 이 프레임은 라이다 데이터의 좌표를 나타내며, 로봇의 기준 프레임("base_link")에 상대적으로 표시됩니다.
3. **left_wheel (왼쪽 바퀴 프레임):** 로봇의 왼쪽 바퀴에 대한 오도메터리 프레임입니다. 이 프레임은 왼쪽 바퀴의 움직임을 나타내며, "base_link"에 상대적으로 위치합니다.
4. **right_wheel (오른쪽 바퀴 프레임):** 로봇의 오른쪽 바퀴에 대한 오도메터리 프레임입니다. 이 프레임은 오른쪽 바퀴의 움직임을 나타내며, "base_link"에 상대적으로 위치합니다.

이렇게 프레임을 명명함으로써 로봇의 센서와 오도메터리 간의 상대적인 위치 및 변환 관계를 명확하게 정의할 수 있습니다. 이러한 프레임은 TF2를 사용하여 로봇 시스템을 모델링하고 제어할 때 중요한 역할을 합니다. 로봇 시스템의 복잡성에 따라 더 많은 프레임을 추가할 수도 있으며, 각 프레임은 로봇의 하드웨어 구성과 관련하여 적절한 이름으로 정의됩니다.



Q. 라이다의 스캔 데이터를 이용해 cartographer 맵을 rviz에 시각화하려면 또 다른 프레임이 필요한가?

A. 라이다의 스캔 데이터를 이용하여 Cartographer와 Rviz를 통해 지도를 시각화하려면 몇 가지 프레임이 추가로 필요할 수 있습니다. 일반적으로 다음과 같은 프레임을 고려할 수 있습니다:

1. **map 프레임:** "map" 프레임은 생성된 지도를 나타냅니다. Cartographer 또는 다른 SLAM (Simultaneous Localization and Mapping) 알고리즘을 사용하여 생성된 지도 정보는 "map" 프레임에 상대적으로 표시됩니다. 이 프레임은 전역 좌표 시스템을 나타내며, 로봇의 초기 위치와 지도 데이터와 관련이 있습니다.
2. **odom 프레임:** "odom" 프레임은 오도메터리 데이터를 나타냅니다. 오도메터리 프레임("left_wheel" 및 "right_wheel" 프레임과 같은)에서 "base_link" 프레임으로의 변환 관계를 표현하는 데 사용됩니다. "base_link"는 로봇의 중심을 나타내며, 로봇의 움직임을 기반으로 "odom" 프레임으로의 변환을 업데이트합니다.
3. **base_scan 프레임:** "base_scan" 프레임은 라이다 스캔 데이터를 나타냅니다. 이 프레임은 라이다 센서("laser_frame")에서 "base_link" 프레임으로의 변환을 나타냅니다. 라이다 데이터는 "base_scan" 프레임에 상대적으로 표시되며, 로봇의 움직임에 따라 업데이트됩니다.

이러한 프레임들은 Cartographer와 Rviz를 사용하여 로봇의 SLAM 및 지도 시각화를 관리하는 데 사용됩니다. 각각의 프레임은 로봇 및 센서 시스템의 구성과 연관되며, TF2 또는 다른 변환 라이브러리를 사용하여 프레임 간의 관계를 정확하게 정의해야 합니다. 이렇게 하면 로봇의 움직임과 센서 데이터를 올바르게 지도에 투영하고 표시할 수 있습니다.



Q. 프레임들의 트리 구조는?

A.              [map]

​                     |

​                [odom]

​                     |

​              [base_link]

​          /                 |                 \

[left_wheel] [right_wheel] [laser_frame]



위의 구조에서:

- "map" 프레임은 전역 좌표 시스템을 나타내며, 지도 정보를 표시합니다.
- "odom" 프레임은 오도메터리 데이터를 나타내며, 로봇의 위치 및 자세를 추정합니다.
- "base_link" 프레임은 로봇의 중심을 나타내며, 로봇의 기준 좌표 프레임입니다.
- "left_wheel" 및 "right_wheel" 프레임은 왼쪽과 오른쪽 바퀴에 대한 오도메터리 프레임입니다.
- "laser_frame" 프레임은 라이다(LIDAR) 센서의 위치와 방향을 나타냅니다.

이러한 프레임들은 로봇의 움직임, 센서 데이터, 지도 정보를 모델링하고 시각화하는 데 사용됩니다. 프레임 간의 변환 관계를 정확하게 설정하면 로봇 시스템을 효과적으로 제어하고 모니터링할 수 있습니다. 이는 로봇 시스템에서 SLAM 및 자율 주행과 같은 작업을 수행하는 데 중요합니다.

라이다(LIDAR)와 오도메트리(오도메터리 데이터 또는 휠 엔코더 데이터)는 주로 "base_link" 프레임에서 상대적인 거리 및 위치 계산에 사용됩니다. 이것은 로봇의 움직임 및 위치 추정과 관련이 있습니다.

여기에서 상세한 설명을 제공하겠습니다:

1. **오도메트리(오도메터리 데이터 또는 휠 엔코더 데이터):** 오도메트리 데이터는 로봇의 바퀴 운동을 기록하는 센서 데이터입니다. 보통 왼쪽 바퀴와 오른쪽 바퀴에 부착된 휠 엔코더를 통해 수집됩니다. 이 데이터는 로봇의 상대적인 움직임을 추정하는 데 사용됩니다. "left_wheel"와 "right_wheel" 프레임은 오도메트리 데이터를 나타내며, 이 데이터를 기반으로 "base_link" 프레임 내에서 로봇의 상대적인 위치와 자세를 업데이트합니다.
2. **라이다(LIDAR):** 라이다 센서는 주변 환경을 스캔하여 거리 정보를 제공합니다. "laser_frame" 프레임에서 라이다 데이터가 수집되며, 이 데이터는 "base_link" 프레임으로의 변환을 통해 로봇의 위치와 자세와 관련된 환경 정보를 얻을 수 있습니다. 라이다 데이터를 "base_link"로 변환하면 로봇의 위치와 자세 정보에 대한 공간적인 참조를 제공합니다.

이렇게 "base_link"를 기준으로 오도메트리와 라이다 데이터를 처리하면 로봇의 움직임 및 환경 정보를 통합하여 제어, 위치 추정 및 지도 작성 등의 작업을 수행할 수 있습니다. 로봇 시스템의 제어 및 자율 주행에는 "base_link" 프레임 내에서 상대적인 거리와 위치 정보가 필수적입니다.



Q. broadcaster와 listener의 주체는 어느 프레임들인가?

A. TF2에서 broadcaster와 listener는 주로 "TF 프레임" 간의 관계를 설정하고 이해하기 위한 도구입니다. 이러한 관계를 설정하고 업데이트하는 주체는 보통 로봇 시스템의 소프트웨어 노드(node)나 프로그램입니다. 이러한 노드 또는 프로그램은 TF2의 broadcaster 역할과 listener 역할을 동시에 수행할 수 있습니다.

Broadcaster(방송자): Broadcaster는 TF2 라이브러리를 사용하여 TF 프레임 간의 관계를 생성하고 업데이트하는 역할을 수행합니다. 이 역할은 로봇 시스템의 소프트웨어에서 실행됩니다. 예를 들어, 로봇의 제어 및 센서 데이터 처리 노드에서 TF2 broadcaster를 사용하여 "base_link"에서 "laser_frame"으로의 변환 관계를 설정할 수 있습니다. 이렇게 설정된 변환 관계는 로봇 시스템의 상황에 따라 주기적으로 업데이트됩니다.

Listener(청취자): Listener는 TF2 라이브러리를 사용하여 TF 프레임 간의 관계를 읽고 실시간으로 모니터링하는 역할을 수행합니다. 이 역할도 로봇 시스템의 소프트웨어에서 실행됩니다. Listener는 broadcaster가 방송한 변환 관계를 감지하고, 이를 통해 로봇 시스템에서 필요한 데이터를 프레임 간에 변환하여 사용합니다. 예를 들어, "laser_frame"에서 "base_link"로의 변환을 통해 라이다 데이터를 로봇의 기준 프레임("base_link")에 맞게 변환하여 사용할 수 있습니다.

요약하면, broadcaster와 listener는 로봇 시스템의 소프트웨어에서 실행되며, TF2 라이브러리를 사용하여 TF 프레임 간의 관계를 설정하고 변환합니다. 이를 통해 로봇 시스템은 다양한 프레임 간의 변환 정보를 이해하고 로봇의 위치, 자세, 센서 데이터 등을 올바르게 처리하고 제어합니다.



Q. Lidar의 Scan data가 broadcaster가 된다면 이의 listener는 어느 프레임인가?

A. 라이다(LIDAR)의 스캔 데이터는 일반적으로 "laser_frame" 프레임에서 broadcaster 역할을 수행합니다. 이 프레임은 라이다 센서의 위치와 방향을 나타냅니다. 따라서 "laser_frame"을 broadcaster로 설정하여 라이다 스캔 데이터를 해당 프레임으로 방송합니다.

라이다 스캔 데이터를 사용하는 listener는 로봇의 기준 좌표 프레임인 "base_link" 프레임이 될 수 있습니다. 이 프레임은 로봇의 중심 또는 기준점을 나타내며, 로봇의 위치와 자세 정보를 기준으로 다른 프레임들과의 상대적인 변환 관계를 나타냅니다. 따라서 "base_link"을 listener로 설정하여 라이다 스캔 데이터를 "base_link"로 변환하고 로봇의 위치에 상대적으로 표시할 수 있습니다.

간단히 말해서, "laser_frame"에서 broadcaster로 방송된 라이다 스캔 데이터를 "base_link"에서 수신하여 로봇의 현재 위치와 자세 정보와 관련된 데이터로 변환하는 것이 일반적인 방법입니다. 이를 통해 로봇의 센서 데이터를 로봇의 기준 프레임으로 정확하게 투영할 수 있습니다.



Q. 오도메트리와 라이다, 그리고 IMU가 사용되다면 이의 tf2 tree 구조는?

A.  

​              [map]

​                 |

​             [odom]

​             /    |    \

 [base_link]  [imu_frame]

​           |

​    [laser_frame]



- "map" 프레임은 전역 좌표 시스템을 나타내며, 지도 정보를 표시합니다.
- "odom" 프레임은 오도메트리 데이터를 나타내며, 로봇의 위치 및 자세를 추정합니다. 이 프레임은 로봇의 위치 추정을 위한 프레임으로 사용됩니다.
- "base_link" 프레임은 로봇의 중심을 나타내며, 로봇의 기준 좌표 프레임입니다.
- "laser_frame" 프레임은 라이다(LIDAR) 센서의 위치와 방향을 나타냅니다. 이 프레임에서 라이다 스캔 데이터가 수집됩니다.
- "imu_frame" 프레임은 IMU(Inertial Measurement Unit) 센서의 데이터를 나타내며, 로봇의 자세 및 가속도 정보를 제공합니다.

이러한 프레임들은 로봇의 움직임 및 자세 추정, 센서 데이터 수집 및 위치 추정과 관련된 작업에서 사용됩니다. 예를 들어, 오도메트리 데이터를 "odom"에서 "base_link"로의 변환 관계를 설정하고, 라이다 스캔 데이터를 "laser_frame"에서 "base_link"로 변환하여 로봇의 현재 위치에 맞게 표시합니다. 마찬가지로, IMU 데이터는 "imu_frame"에서 "base_link"로 변환하여 로봇의 자세 및 가속도 정보를 로봇의 기준 좌표 프레임에 맞게 표시합니다.

이렇게 구성된 TF2 트리는 로봇 시스템의 자세 및 위치 추정, 센서 데이터 처리 및 제어에 필요한 변환 관계를 정의하고 모델링하는 데 사용됩니다.



Q. 왜 laser_frame만 base_link의 자손 트리이고 imu는 odom의 자식 트리인가?

A. "laser_frame"이 "base_link"의 자손 트리(하위 트리)에 있고 "imu_frame"이 "odom"의 자식 트리(상위 트리)에 있는 이유는 센서의 위치와 관련된 차이와 센서 데이터의 활용 방법 때문입니다. 이러한 구성은 로봇 시스템의 센서 구성과 센서 데이터 처리 방식에 따라 결정됩니다.

1. **라이다(LIDAR) 센서 ("laser_frame"):**

- 라이다 센서는 주로 로봇의 외부에 부착되어 로봇 주변 환경을 스캔하는 역할을 합니다. 따라서 라이다 데이터는 로봇의 기준 좌표 프레임("base_link")에서 수집되며, "laser_frame" 프레임에서 나타냅니다.
- 로봇의 기준 좌표 프레임("base_link")에서 "laser_frame"으로의 변환 관계를 설정하면, 라이다 데이터는 로봇의 현재 위치와 자세에 상대적으로 표시됩니다. 이렇게 하면 로봇의 움직임에 따라 라이다 데이터가 적절하게 변환되어 환경 지도에 맞게 투영됩니다.

1. **IMU (Inertial Measurement Unit) 센서 ("imu_frame"):**

- IMU 센서는 로봇의 가속도 및 자세 정보를 제공합니다. 이러한 정보는 주로 로봇의 움직임 및 자세 추정에 사용됩니다.
- IMU 센서 데이터는 주로 로봇의 오도메트리 데이터와 결합하여 로봇의 위치와 자세를 추정하는 데 활용됩니다. 이 때, "odom" 프레임은 로봇의 오도메트리 정보를 나타냅니다. 따라서 "imu_frame"은 "odom" 프레임의 자식 트리에 위치하여, 오도메트리 데이터와 함께 사용됩니다.

센서 데이터의 활용 방법과 위치 결정은 로봇 시스템의 특성 및 응용에 따라 다를 수 있으며, 위에서 설명한 구성은 일반적인 경우에 대한 예시입니다. 로봇 시스템의 복잡성 및 요구 사항에 따라 프레임 트리 구조와 변환 관계를 조정할 수 있습니다.



Q. fixed_frame은 어떻게 되나?

A. ROS(Robot Operating System) 및 관련 라이브러리에서 "fixed_frame"은 주로 시각화 도구나 로봇 모니터링 도구에서 사용되는 프레임 중 하나입니다. "fixed_frame"은 시각화 도구에서 특정 시점의 프레임을 고정된 위치로 설정하는 데 사용됩니다.

일반적으로 "fixed_frame"은 시각화 도구(예: RViz)를 사용하여 로봇 및 센서 데이터를 표시할 때 중요한 역할을 합니다. 이 프레임은 시각화 도구를 통해 로봇 시스템의 상대적인 위치와 자세 정보를 표시하는 데 사용됩니다. "fixed_frame"을 설정하면 해당 프레임을 기준으로 다른 프레임들의 위치 및 자세 정보가 표시되며, 로봇의 모든 다른 프레임들은 이 "fixed_frame"에 상대적으로 표시됩니다.

예를 들어, 로봇 시스템을 RViz에서 시각화할 때 "fixed_frame"을 "map"으로 설정하면 로봇의 모든 다른 프레임들은 "map"에 상대적으로 표시됩니다. 따라서 지도 정보와 로봇의 위치, 자세 정보가 "map" 프레임을 기준으로 올바르게 표시됩니다.

"fixed_frame"은 로봇 시스템을 시각화하거나 모니터링할 때 특히 유용하며, 로봇 모델의 상대적인 위치와 자세 정보를 이해하기 쉽게 표시하는 데 도움이 됩니다.



Q. laser_frame는 어떻한 메시지를 broadcast하나?

A. 라이다(LIDAR) 센서의 "laser_frame"에는 일반적으로 라이다 스캔 데이터를 TF2 변환 메시지로 broadcast합니다. 이러한 변환 메시지는 로봇 시스템에서 라이다 데이터를 로봇의 기준 좌표 프레임("base_link" 등)으로 변환하는 데 사용됩니다.

일반적으로 다음과 같은 변환 메시지가 "laser_frame"에서 "base_link"로 broadcast됩니다:

- 변환 프레임 ID (frame_id): "laser_frame"
- 대상 프레임 ID (child_frame_id): "base_link"
- 변환 행렬 (transform matrix): 이것은 "laser_frame"에서 "base_link"로의 변환 관계를 나타내며, 로봇의 위치와 자세 정보를 포함합니다.

이 변환 메시지는 로봇 시스템의 제어 및 센서 데이터 처리에 사용됩니다. 예를 들어, 로봇의 움직임에 따라 "base_link" 프레임이 업데이트될 때마다 "laser_frame"에서 "base_link"로의 변환 관계도 업데이트됩니다. 이를 통해 로봇의 현재 위치 및 자세 정보에 맞게 라이다 데이터를 표시할 수 있습니다.

실제로 ROS 노드에서 TF2 broadcaster를 사용하여 이러한 변환 메시지를 생성하고 "laser_frame"에서 "base_link"로 broadcast하는 것이 일반적입니다. 이러한 broadcast를 통해 로봇 시스템은 로봇의 위치와 라이다 데이터 간의 변환을 관리하고 센서 데이터를 올바르게 처리할 수 있습니다.



Q. broadcast할때의 msg 타입은 어떻게 정의 되어 있나?

A. ROS 2에서 TF2 변환 메시지를 broadcast할 때는 **geometry_msgs/TransformStamped** 메시지 타입을 사용합니다. 이 메시지는 변환 관계를 정의하는 데 사용됩니다. **geometry_msgs/TransformStamped** 메시지는 다음과 같이 정의됩니다:

```
# geometry_msgs/TransformStamped.msg

# This expresses a transform from coordinate frame named in the child_frame_id
# to the coordinate frame named in the header of the message.
Header header
string child_frame_id
Transform transform
```

**TransformStamped** 메시지는 다음 구성 요소로 구성됩니다:

- **header**: 메시지의 헤더 정보를 포함하는 부분으로, 메시지의 타임스탬프 및 프레임 ID 정보를 포함합니다.
- **child_frame_id**: 변환의 하위 프레임 ID로, 변환되는 객체의 프레임을 식별합니다.
- **transform**: 실제 변환 행렬 정보를 담고 있는 부분으로, 변환 관계를 나타냅니다.

이 메시지를 사용하여 "laser_frame"에서 "base_link"로의 변환을 정의하고 TF2 broadcaster를 사용하여 브로드캐스트합니다. 예를 들어, Python에서는 다음과 같은 코드를 사용하여 메시지를 생성하고 발행할 수 있습니다:

```
import rclpy
from geometry_msgs.msg import TransformStamped

# Initialize a node
rclpy.init()
node = rclpy.create_node('tf2_broadcaster')

# Create a TransformStamped message
transform_msg = TransformStamped()

# Fill in the message fields
transform_msg.header.stamp = node.get_clock().now().to_msg()
transform_msg.header.frame_id = 'base_link'
transform_msg.child_frame_id = 'laser_frame'

# Define the transformation matrix (rotation and translation)
# transform_msg.transform contains the transformation information
transform_msg.transform.translation.x = 1.0  # Example translation
transform_msg.transform.rotation.w = 1.0      # Example rotation (Quaternion)

# Broadcast the transform
tf_broadcaster = node.create_publisher(TransformStamped, '/tf', 10)
tf_broadcaster.publish(transform_msg)

# Spin the node to keep it active
rclpy.spin(node)
```

이 코드는 *"base_link"에서 "laser_frame"으로의 변환 메시지를 생성*하고 **/tf** 토픽을 통해 TF2 변환 메시지를 발행합니다. 이러한 메시지를 정기적으로 업데이트하여 로봇 시스템의 변환 관계를 관리하고, 로봇 시스템에서 센서 데이터를 올바르게 처리할 수 있습니다.



Q. laser_frame의 msg type은?

A. "laser_frame"은 일반적으로 **sensor_msgs/LaserScan** 메시지 타입을 사용하여 라이다(LIDAR) 스캔 데이터를 표현합니다. **sensor_msgs/LaserScan** 메시지는 라이다 스캔 데이터의 각도, 거리 및 강도 정보를 포함하는 메시지로 정의됩니다.

다음은 **sensor_msgs/LaserScan** 메시지의 내용입니다:

```
# sensor_msgs/LaserScan.msg

Header header           # 헤더 정보
float32 angle_min       # 최소 스캔 각도 (라디안)
float32 angle_max       # 최대 스캔 각도 (라디안)
float32 angle_increment # 스캔 각도 간격 (라디안)
float32 time_increment  # 스캔 데이터 간의 시간 간격 (초)
float32 scan_time       # 스캔 한 번 당 걸리는 시간 (초)
float32 range_min       # 측정 가능한 최소 거리 (미터)
float32 range_max       # 측정 가능한 최대 거리 (미터)
float32[] ranges        # 각 레이저 빔의 거리 데이터 (미터)
float32[] intensities   # 각 레이저 빔의 강도 데이터 (옵션)
```

**sensor_msgs/LaserScan** 메시지에는 스캔 데이터의 기본 정보뿐만 아니라 각도, 거리 및 강도 데이터가 포함되어 있습니다. 이 메시지는 라이다 센서가 환경을 스캔한 결과를 나타냅니다. "laser_frame"에서 발행된 이 메시지를 TF2 broadcaster를 사용하여 로봇의 기준 좌표 프레임("base_link" 등)으로 변환하고, 이 데이터를 사용하여 로봇의 환경 지도를 작성하거나 장애물 회피와 같은 작업을 수행할 수 있습니다.



Q. 오도메트리의 메시지 타입은?

A. 오도메트리 데이터는 ROS에서 주로 **nav_msgs/Odometry** 메시지 타입으로 표현됩니다. **nav_msgs/Odometry** 메시지는 로봇의 위치와 자세 정보를 나타내며, 로봇의 움직임을 추정하는 데 사용됩니다.

다음은 **nav_msgs/Odometry** 메시지의 내용입니다:

```
# nav_msgs/Odometry.msg

Header header            # 헤더 정보
string child_frame_id    # 하위 프레임 ID
geometry_msgs/PoseWithCovariance pose    # 위치 정보
geometry_msgs/TwistWithCovariance twist  # 속도 정보
```

- **header**: 메시지의 헤더 정보를 포함하는 부분으로, 메시지의 타임스탬프와 프레임 ID 정보를 포함합니다.
- **child_frame_id**: 하위 프레임 ID로, 오도메트리 정보가 적용되는 프레임을 식별합니다.
- **pose**: 로봇의 위치 정보를 나타내는 부분으로, **geometry_msgs/PoseWithCovariance** 메시지를 사용하여 로봇의 위치와 자세를 정의합니다. 이 부분은 로봇의 위치를 3D 공간에서 표현합니다.
- **twist**: 로봇의 속도 정보를 나타내는 부분으로, **geometry_msgs/TwistWithCovariance** 메시지를 사용하여 로봇의 선속도와 각속도를 정의합니다.

이 메시지는 로봇의 움직임을 추적하고 로봇의 현재 위치 및 자세 정보를 포함합니다. 오도메트리 메시지는 로봇 시스템에서 로봇 제어, 자율 주행, SLAM (Simultaneous Localization and Mapping) 등의 작업에 중요한 역할을 합니다.



Q. 이러한 정보를 이용해 라이다에서 라이다 데이터를 broasdcast하는 노드를 만든다면 코드는?

A. 라이다(LIDAR)에서 라이다 데이터를 받아서 TF2 변환 메시지로 broadcast하는 노드를 만들려면 Python을 사용하여 다음과 같은 코드를 작성할 수 있습니다. 이 코드는 **sensor_msgs/LaserScan** 메시지를 구독하고, 해당 데이터를 TF2 변환 메시지로 변환한 후 TF2 broadcaster를 사용하여 브로드캐스트합니다.

```
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan
from geometry_msgs.msg import TransformStamped
import tf2_ros
from tf2_geometry_msgs import do_transform_cloud

class LidarToTFNode(Node):

    def __init__(self):
        super().__init__('lidar_to_tf_node')
        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)

        # Subscribe to the LaserScan topic
        self.subscription = self.create_subscription(
            LaserScan,
            '/your/laser_scan_topic',  # Replace with the actual laser scan topic
            self.laser_scan_callback,
            10  # Adjust the queue size as needed
        )
        self.subscription

    def laser_scan_callback(self, msg):
        # Create a TF2 transform message
        transform_msg = TransformStamped()
        transform_msg.header.stamp = self.get_clock().now().to_msg()
        transform_msg.header.frame_id = 'base_link'  # Replace with the parent frame ID
        transform_msg.child_frame_id = 'laser_frame'  # Replace with the child frame ID (LIDAR frame)

        # Set the translation (position) of the transform
        transform_msg.transform.translation.x = 1.0  # Example translation in X-axis
        transform_msg.transform.translation.y = 0.0  # Example translation in Y-axis
        transform_msg.transform.translation.z = 0.0  # Example translation in Z-axis

        # Set the rotation (orientation) of the transform (identity quaternion in this example)
        transform_msg.transform.rotation.x = 0.0
        transform_msg.transform.rotation.y = 0.0
        transform_msg.transform.rotation.z = 0.0
        transform_msg.transform.rotation.w = 1.0

        # Broadcast the transform
        self.tf_broadcaster.sendTransform(transform_msg)

def main(args=None):
    rclpy.init(args=args)
    node = LidarToTFNode()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

위의 코드에서 **/your/laser_scan_topic** 부분을 실제 라이다 스캔 데이터가 게시되는 토픽 이름으로 대체해야 합니다. 이 코드는 LIDAR 프레임("laser_frame")을 "base_link" 프레임에 상대적으로 위치시키는 변환 메시지를 생성하고 TF2 broadcaster를 사용하여 이 변환 메시지를 발행합니다.

필요에 따라 변환 메시지의 위치와 방향을 설정하고, 라이다 데이터와 관련된 추가 정보를 고려하여 코드를 수정할 수 있습니다.



Q. 좌우 모터의 오도메트리 정보를 broadcast하는 노드의 코드는?

A. 좌우 모터의 오도메트리 정보를 broadcast하는 노드의 코드를 작성하려면 먼저 각 모터의 엔코더 데이터 또는 움직임 정보를 사용하여 오도메트리 데이터를 생성하고 이를 TF2 변환 메시지로 broadcast해야 합니다. 이 코드 예제는 좌우 모터의 오도메트리 데이터를 생성하고 이를 "base_link" 프레임에 상대적으로 위치시키는 변환 메시지로 만들고 broadcast하는 Python 코드를 제공합니다.

```
import rclpy
from rclpy.node import Node
from nav_msgs.msg import Odometry
from geometry_msgs.msg import TransformStamped
import tf2_ros
import math

class MotorOdomToTFNode(Node):

    def __init__(self):
        super().__init__('motor_odom_to_tf_node')
        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)

        # Create a publisher for the Odometry message
        self.odom_publisher = self.create_publisher(
            Odometry,
            '/your/odom_topic',  # Replace with the actual Odometry topic
            10  # Adjust the queue size as needed
        )

        # Initialize the Odometry message
        self.odom_msg = Odometry()
        self.odom_msg.header.frame_id = 'base_link'  # Parent frame ID
        self.odom_msg.child_frame_id = 'wheel_odom'  # Child frame ID (for motor odom)

        # Initialize motor odometry values (you need to replace these with actual values)
        self.left_wheel_distance = 0.0  # Left wheel distance traveled (meters)
        self.right_wheel_distance = 0.0  # Right wheel distance traveled (meters)
        self.wheelbase_width = 0.2  # Wheelbase width (distance between left and right wheels) in meters

        # Timer for publishing motor odometry
        self.publish_timer = self.create_timer(
            1.0,  # Publish rate (1 Hz in this example)
            self.publish_odometry
        )

    def publish_odometry(self):
        # Calculate robot linear and angular velocity based on wheel odometry
        linear_velocity = (self.left_wheel_distance + self.right_wheel_distance) / 2.0
        angular_velocity = (self.right_wheel_distance - self.left_wheel_distance) / self.wheelbase_width

        # Update the Odometry message
        self.odom_msg.header.stamp = self.get_clock().now().to_msg()
        self.odom_msg.twist.twist.linear.x = linear_velocity
        self.odom_msg.twist.twist.angular.z = angular_velocity

        # Publish the Odometry message
        self.odom_publisher.publish(self.odom_msg)

        # Create a TF2 transform message for motor odom
        transform_msg = TransformStamped()
        transform_msg.header.stamp = self.get_clock().now().to_msg()
        transform_msg.header.frame_id = 'base_link'  # Parent frame ID
        transform_msg.child_frame_id = 'wheel_odom'  # Child frame ID (for motor odom)

        # Set the translation (position) of the transform
        transform_msg.transform.translation.x = self.left_wheel_distance  # Adjust as needed
        transform_msg.transform.translation.y = self.right_wheel_distance  # Adjust as needed
        transform_msg.transform.translation.z = 0.0

        # Set the rotation (orientation) of the transform (identity quaternion in this example)
        transform_msg.transform.rotation.x = 0.0
        transform_msg.transform.rotation.y = 0.0
        transform_msg.transform.rotation.z = 0.0
        transform_msg.transform.rotation.w = 1.0

        # Broadcast the transform
        self.tf_broadcaster.sendTransform(transform_msg)

def main(args=None):
    rclpy.init(args=args)
    node = MotorOdomToTFNode()
    rclpy.spin(node)
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

위의 코드에서 **/your/odom_topic** 부분을 실제 오도메트리 데이터가 게시되는 토픽 이름으로 대체해야 합니다. 이 코드는 좌우 모터의 오도메트리 데이터를 생성하고 이를 TF2 변환 메시지로 broadcast하며, 동시에 오도메트리 메시지를 발행하여 로봇의 선속도와 각속도를 전달합니다.

실제로 로봇의 모터 오도메트리 데이터는 로봇의 구조와 모터 엔코더 정보에 따라 다를 수 있으므로 코드를 해당 로봇의 요구 사항에 맞게 수정해야 합니다.



Q. 이 두노드를 이용해 rviz에서 cartograper MAP을 시각화 하기 launch 의 코드는?

A. Cartographer를 사용하여 생성된 지도(map)를 RViz에서 시각화하려면, Cartographer로부터 지도 데이터를 RViz로 전송하는 launch 파일을 만들어야 합니다. 이를 위해 Cartographer에서 지도 데이터를 RViz로 전송하기 위한 노드를 실행하고, RViz를 실행하는 두 가지 노드를 launch 파일에 포함해야 합니다.

아래는 이러한 작업을 수행하는 간단한 ROS 2 launch 파일의 예제입니다. 이 예제에서는 Cartographer로부터 지도 데이터를 RViz로 전송하는 **cartographer_assets_writer**와 RViz를 실행하는 **rviz2**를 사용합니다.

```
# cartographer.launch.py

import launch
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument
from launch.substitutions import LaunchConfiguration
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        # Declare launch arguments if needed
        DeclareLaunchArgument('use_sim_time', default_value='false',
                              description='Use simulation (Gazebo) time if true'),

        # Launch Cartographer node
        Node(
            package='your_cartographer_package',
            executable='cartographer_node',
            name='cartographer_node',
            output='screen',
            parameters=[{'use_sim_time': LaunchConfiguration('use_sim_time')}],
        ),
    ])
```

로봇 제작시 실제 필요한 과정을 Q&A 형식으로 순차적으로  정리해 보았다. 
